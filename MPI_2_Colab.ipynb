{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scatter and scatter v\n",
        "\n",
        "1. length: number of values to each processes\n",
        "2. disp: starting location of data to each processes\n",
        "\n",
        "Scatterv example:\n",
        " - x: 0 1 2 3 4 5 6\n",
        " - P0:\n",
        "    - disp: 0\n",
        "    - length: 2\n",
        "    - start from x[0], send x[0] and x[1]\n",
        " - P1:\n",
        "    - disp: 2\n",
        "    - length: 2\n",
        "    - start from x[2], send x[2] and x[3]\n",
        " - P2:\n",
        "    - disp: 4\n",
        "    - length: 1\n",
        "    - start from x[4], send x[4]\n",
        " - P3:\n",
        "    - disp: 5\n",
        "    - length: 1\n",
        "    - start from x[5], send x[5]"
      ],
      "metadata": {
        "id": "VK-OcBRtZYhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main_1.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   if(numprocs != 4)\n",
        "   {\n",
        "      if(myid == 0)\n",
        "      {\n",
        "         std::cout << \"Error: This program requires exactly 4 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   int sendcount[4] = {2,2,1,1};\n",
        "   int displs[4] = {0,2,4,5};\n",
        "   float x[10];\n",
        "   for(int i = 0; i < 10; i++)\n",
        "   {\n",
        "      x[i] = i;\n",
        "   }\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Before Scatterv, processor \" << myid << \" has x = \";\n",
        "      for(int i = 0; i < 10; i++)\n",
        "      {\n",
        "         std::cout << x[i] << \" \";\n",
        "      }\n",
        "      std::cout << std::endl;\n",
        "   }\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "   float *y = new float[sendcount[myid]];\n",
        "   MPI_Scatterv(x, sendcount, displs, MPI_FLOAT, y, sendcount[myid], MPI_FLOAT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Scatterv, processor \" << myid << \" has y = \";\n",
        "         for(int i = 0; i < sendcount[myid]; i++)\n",
        "         {\n",
        "            std::cout << y[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "2A-5p95uZ62L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicxx main_1.cpp -o main_1.ex"
      ],
      "metadata": {
        "id": "LdpcfXccae10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main_1.ex"
      ],
      "metadata": {
        "id": "CdLnCLO5afnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question:\n",
        "\n",
        "What if we have to send\n",
        "\n",
        "0 -> P0\n",
        "\n",
        "3 4 -> P1\n",
        "\n",
        "6 7 -> P2\n",
        "\n",
        "9 -> p3"
      ],
      "metadata": {
        "id": "3eZecYWL0II3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main_1.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   if(numprocs != 4)\n",
        "   {\n",
        "      if(myid == 0)\n",
        "      {\n",
        "         std::cout << \"Error: This program requires exactly 4 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   // TODO: How to modify here?\n",
        "   // int sendcount[4] = {2,2,1,1};\n",
        "   // int displs[4] = {0,2,4,5};\n",
        "   // END TODO\n",
        "\n",
        "   float x[10];\n",
        "   for(int i = 0; i < 10; i++)\n",
        "   {\n",
        "      x[i] = i;\n",
        "   }\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Before Scatterv, processor \" << myid << \" has x = \";\n",
        "      for(int i = 0; i < 10; i++)\n",
        "      {\n",
        "         std::cout << x[i] << \" \";\n",
        "      }\n",
        "      std::cout << std::endl;\n",
        "   }\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "   float *y = new float[sendcount[myid]];\n",
        "   MPI_Scatterv(x, sendcount, displs, MPI_FLOAT, y, sendcount[myid], MPI_FLOAT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Scatterv, processor \" << myid << \" has y = \";\n",
        "         for(int i = 0; i < sendcount[myid]; i++)\n",
        "         {\n",
        "            std::cout << y[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "XAgeyotw1JHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicxx main_1.cpp -o main_1.ex"
      ],
      "metadata": {
        "id": "_KnLbyJG1hR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main_1.ex"
      ],
      "metadata": {
        "id": "OtFrORZC1hlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-blocking Send and Recv\n",
        "\n",
        "1. Use MPI_Ixxx\n",
        "2. MPI_Wait for the request\n",
        "3. MPI_Test"
      ],
      "metadata": {
        "id": "3Uz_U5D_1jRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main_2.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "#define MESSAGE_SIZE 10000\n",
        "const bool blocking0 = true;\n",
        "const bool blocking1 = false;\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int myid, numprocs;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "    if (numprocs != 2) {\n",
        "        if (myid == 0) {\n",
        "            std::cout << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "        }\n",
        "        MPI_Finalize();\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    int send_data[MESSAGE_SIZE];\n",
        "    int recv_data[MESSAGE_SIZE];\n",
        "    for (int i = 0; i < MESSAGE_SIZE; i++) {\n",
        "        send_data[i] = i + myid * MESSAGE_SIZE;\n",
        "        recv_data[i] = -1;\n",
        "    }\n",
        "    MPI_Request send_request, recv_request;\n",
        "    MPI_Status send_status, recv_status;\n",
        "\n",
        "    if (myid == 0)\n",
        "    {\n",
        "        if (blocking0)\n",
        "        {\n",
        "          std::cout << \"Processor 0 is using blocking send and receive.\" << std::endl;\n",
        "          MPI_Send(&send_data, MESSAGE_SIZE, MPI_INT, 1, 200, MPI_COMM_WORLD);\n",
        "          MPI_Recv(&recv_data, MESSAGE_SIZE, MPI_INT, 1, 100, MPI_COMM_WORLD, &recv_status);\n",
        "        }\n",
        "        else\n",
        "        {\n",
        "          std::cout << \"Processor 0 is using non-blocking send and receive.\" << std::endl;\n",
        "          MPI_Isend(&send_data, MESSAGE_SIZE, MPI_INT, 1, 200, MPI_COMM_WORLD, &send_request);\n",
        "          MPI_Irecv(&recv_data, MESSAGE_SIZE, MPI_INT, 1, 100, MPI_COMM_WORLD, &recv_request);\n",
        "\n",
        "          MPI_Wait(&send_request, &send_status);\n",
        "          MPI_Wait(&recv_request, &recv_status);\n",
        "        }\n",
        "\n",
        "        std::cout << \"Processor 0 sent \" << send_data[0] << \" and received \" << recv_data[0] << std::endl;\n",
        "    } else if (myid == 1)\n",
        "    {\n",
        "        if(blocking1)\n",
        "        {\n",
        "          std::cout << \"Processor 1 is using blocking send and receive.\" << std::endl;\n",
        "          MPI_Send(&send_data, MESSAGE_SIZE, MPI_INT, 0, 100, MPI_COMM_WORLD);\n",
        "          MPI_Recv(&recv_data, MESSAGE_SIZE, MPI_INT, 0, 200, MPI_COMM_WORLD, &recv_status);\n",
        "        }\n",
        "        else\n",
        "        {\n",
        "          std::cout << \"Processor 1 is using non-blocking send and receive.\" << std::endl;\n",
        "          MPI_Isend(&send_data, MESSAGE_SIZE, MPI_INT, 0, 100, MPI_COMM_WORLD, &send_request);\n",
        "          MPI_Irecv(&recv_data, MESSAGE_SIZE, MPI_INT, 0, 200, MPI_COMM_WORLD, &recv_request);\n",
        "\n",
        "          MPI_Wait(&send_request, &send_status);\n",
        "          MPI_Wait(&recv_request, &recv_status);\n",
        "        }\n",
        "\n",
        "        std::cout << \"Processor 1 sent \" << send_data[0] << \" and received \" << recv_data[0] << std::endl;\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "_s692iHX1qhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicxx main_2.cpp -o main_2.ex"
      ],
      "metadata": {
        "id": "VXgXn9IU2TYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./main_2.ex"
      ],
      "metadata": {
        "id": "8ygSL6gY2TLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}