{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaVTR4N11ADT"
      },
      "source": [
        "# 1. Hello World\n",
        "\n",
        "Key components of MPI:\n",
        "  - `<mpi.h>`: Header file of MPI, must include this\n",
        "  - `MPI_Init`: Initialization of MPI, must call before any other MPI routines.\n",
        "  - `MPI_Comm_size`: Get the total number of processors. `mpirun -np 4 ./main.ex` get the number `4`\n",
        "  - `MPI_Comm_rank`: Get the rank (the number 0, 1, 2 ... of P0, P1, P2, ...)\n",
        "  - `MPI_Finalize()`: Pair with initialization.\n",
        "\n",
        "In the following example, you will see the basic usage of MPI.\n",
        "Note that physical processor name is not the same as logical processor rank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muMijRp-KKqT"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  MPI_Init(&argc, &argv);\n",
        "\n",
        "  int myid, numprocs;\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "  char processor_name[MPI_MAX_PROCESSOR_NAME];\n",
        "  int name_len;\n",
        "  MPI_Get_processor_name(processor_name, &name_len);\n",
        "\n",
        "  std::cout << \"Hello world from processor \" << processor_name << \", rank \" << myid << \" out of \" << numprocs << \" processors\" << std::endl;\n",
        "\n",
        "  MPI_Finalize();\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofe1qUMoKrDZ"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7hUqFo1KxI6"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI8GmjJC2bGi"
      },
      "source": [
        "# 2. Combine MPI with OpenMP\n",
        "\n",
        "You can combine MPI with OpenMP. Each MPI processes is able to use openmp.\n",
        "\n",
        " - If you nave np MPI processes and p OpenMP thread each, you will have np*p cores working together.\n",
        " - Try the following code and see if it works as you expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRAs8toGOAuk"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(argc != 2)\n",
        "   {\n",
        "      omp_set_num_threads(2);\n",
        "   }\n",
        "   else\n",
        "   {\n",
        "      omp_set_num_threads(atoi(argv[1]));\n",
        "   }\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "      std::cout << \"Number of threads: \" << omp_get_max_threads() << std::endl;\n",
        "   }\n",
        "\n",
        "   int *x = new int[numprocs];\n",
        "   for(int i = 0; i < numprocs; i++)\n",
        "   {\n",
        "      x[i] = i + myid * numprocs;\n",
        "   }\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         #pragma omp parallel\n",
        "         {\n",
        "            int tid = omp_get_thread_num();\n",
        "            #pragma omp critical\n",
        "            {\n",
        "               std::cout << \"Processor \" << myid << \" thread \" << tid << \" has x = \";\n",
        "               for(int i = 0; i < numprocs; i++)\n",
        "               {\n",
        "                  std::cout << x[i] << \" \";\n",
        "               }\n",
        "               std::cout << std::endl;\n",
        "            }\n",
        "         }\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   sleep(1);\n",
        "\n",
        "   for(int i = 0; i < numprocs; i++)\n",
        "   {\n",
        "      if(myid == i)\n",
        "      {\n",
        "         #pragma omp parallel\n",
        "         {\n",
        "            int tid = omp_get_thread_num();\n",
        "            #pragma omp critical\n",
        "            {\n",
        "               std::cout << \"x[0] on processor \" << myid << \" thread \" << tid << \" is \" << x[0] << std::endl;\n",
        "            }\n",
        "         }\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WfCuF_0OD28"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex -fopenmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwaq0sn0OFJz"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abhp65vB3EMt"
      },
      "source": [
        "# 3. MPI Communicator\n",
        "\n",
        " - Communicator are group of processors. The same processor can have different rank/myid in different communicator.\n",
        " - In the example below, we group processor i with i+1 for all even i. You can see different rank in MPI_COMM_WORLD and the new comm.\n",
        " - We will revisit this later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn7dWRsZNOni"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  MPI_Init(&argc, &argv);\n",
        "\n",
        "  int rank, size;\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "  if (size % 2 != 0) {\n",
        "    if (rank == 0) {\n",
        "      std::cerr << \"Error: Number of processors must be even.\" << std::endl;\n",
        "    }\n",
        "    MPI_Finalize();\n",
        "    return 1;\n",
        "  }\n",
        "\n",
        "  int color = rank / 2;\n",
        "  MPI_Comm new_comm;\n",
        "  MPI_Comm_split(MPI_COMM_WORLD, color, rank, &new_comm);\n",
        "\n",
        "  int new_rank, new_size;\n",
        "  MPI_Comm_rank(new_comm, &new_rank);\n",
        "  MPI_Comm_size(new_comm, &new_size);\n",
        "\n",
        "  std::cout << \"Processor \" << rank << \" (world rank) is now in communicator \" << color\n",
        "            << \" with rank \" << new_rank << \" (local rank) and size \" << new_size\n",
        "            << std::endl;\n",
        "\n",
        "  MPI_Comm_free(&new_comm);\n",
        "\n",
        "  MPI_Finalize();\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zENlz5RINrdj"
      },
      "outputs": [],
      "source": [
        "!mpiCC main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhELRyi6Ns-4"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HGZzKiR3sez"
      },
      "source": [
        "# 4. Next we introduce the bcast operation in MPI.\n",
        "\n",
        " - Bcast: send information from root to all other processors.\n",
        " - In the code below, we bcast the value of x from processor number 0 to all other processors. You can see a change of value afterward.\n",
        "\n",
        "Bcast:\n",
        "  - Pointer to the data: data to be bcase, this is also where other processes receive data. For a number use & to get address\n",
        "  - Length of the data: for single number is it 1. You can also send array of longer size.\n",
        "  - Data type: int, float\n",
        "  - Root: the processor that is sending data out\n",
        "  - MPI_Comm\n",
        "\n",
        "Questions: How to modify the code to send from processor 1 instead of processor 0?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOvqGLcIQ3On"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   int x = myid;\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before Bcast, processor \" << myid << \" has x = \" << x << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Bcast(&x, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Bcast, processor \" << myid << \" has x = \" << x << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKnbJ6aXQ-D_"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INBGySpXQ__3"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbCugaU94ID5"
      },
      "source": [
        "# 5.1 Next, we start talking about send and recv\n",
        "\n",
        " - We start from the blocking version of send and receive.\n",
        " - This is the simplest routines.\n",
        "\n",
        "Sender:\n",
        " - pointer to the data: for number use `&` to get address\n",
        " - send data length: length of the array. If a number, set to 1.\n",
        " - send data type: integer? fp32?\n",
        " - dest: where the message goes to\n",
        " - tag: message unique id. If send recv tag does not match data will not be received.\n",
        " - MPI_Comm: the mpi communicator\n",
        "\n",
        "Receiver:\n",
        " - pointer to the data\n",
        " - recv data length:\n",
        " - recv data type: type of data that is being received\n",
        " - source: where the message is from\n",
        " - tag: message unique id.\n",
        " - MPI_Comm: the communicator\n",
        " - MPI_Status: special structure to get some useful information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-pwKOusbY-l"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if (numprocs != 2) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   if (myid == 0) {\n",
        "      int message = 123;\n",
        "      MPI_Send(&message, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 0 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 1) {\n",
        "      int received_message;\n",
        "      MPI_Recv(&received_message, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 1 received message: \" << received_message << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhmtoEMxdYV-"
      },
      "outputs": [],
      "source": [
        "!mpiCC main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmPhQTgWdZBd"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEMysR0e_JmI"
      },
      "source": [
        "# 5.2 Examples of dead lock\n",
        "\n",
        " - Unpaired communication (send with no receiver)\n",
        "    - P0:\n",
        "          send to P1\n",
        "    - P1:\n",
        "          no recv of the send\n",
        "    - Be very careful in your code. This can be caused by tag mismatch, communicator mismatch, and so on.\n",
        " - both pe blocked somewhere\n",
        "    - P0:\n",
        "          send message 0 to P1\n",
        "          recv message 1 from P1\n",
        "    - P1:\n",
        "          send message 1 to P0\n",
        "          recv message 0 from P0\n",
        "    - The code will block at the send commands, as the recv commands will never be executed\n",
        " - And many more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1YECjvZca1d"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Dead lock due to blocking at the MPI_Recv\n",
        "// Question: How to fix the following code?\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if (numprocs != 2) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   if (myid == 0) {\n",
        "      int message = 123;\n",
        "      int received_message;\n",
        "      MPI_Recv(&received_message, 1, MPI_INT, 1, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 0 received message: \" << received_message << std::endl;\n",
        "      MPI_Send(&message, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 0 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 1) {\n",
        "      int message = 321;\n",
        "      int received_message;\n",
        "      MPI_Recv(&received_message, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 1 received message: \" << received_message << std::endl;\n",
        "      MPI_Send(&message, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 1 sent message: \" << message << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxmc3V-2AlIp"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Unpaired send recv due to tag mismatch\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if (numprocs != 2) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   if (myid == 0) {\n",
        "      int message = 123;\n",
        "      MPI_Send(&message, 1, MPI_INT, 1, 111, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 0 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 1) {\n",
        "      int received_message;\n",
        "      MPI_Recv(&received_message, 1, MPI_INT, 0, 222, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 1 received message: \" << received_message << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsh6iADuAzzl"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Unpaired send recv due to communicator mismatch\n",
        "// Even if they include same list of processors!\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   MPI_Comm new_world;\n",
        "   MPI_Comm_dup(MPI_COMM_WORLD, &new_world);\n",
        "\n",
        "   if (numprocs != 2) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   if (myid == 0) {\n",
        "      int message = 123;\n",
        "      MPI_Send(&message, 1, MPI_INT, 1, 0, new_world);\n",
        "      std::cout << \"Processor 0 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 1) {\n",
        "      int received_message;\n",
        "      MPI_Recv(&received_message, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 1 received message: \" << received_message << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMW1uittcHbg"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BflxAkcLd1XK"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXZeZ2S9KwZQ"
      },
      "source": [
        "# 5.3 Probe\n",
        "\n",
        " - In the following code we have three processes, mimicking the following scenario:\n",
        "    - Three processes running some tasks in parallel\n",
        "    - Processor 0 then need to gather results and do some post processing\n",
        " - In the first example, we use recv\n",
        "    - Recv from P1 first\n",
        "    - Must wait for P1 to complete\n",
        "    - Total time:\n",
        "      1. 5 seconds for P1 to finish parallel task\n",
        "      2. 6 seconds (2*3) for handling data after that\n",
        "      3. 11 seconds in total\n",
        " - In the second example, we use probe\n",
        "    - Recv from whatever comes first. In our example it is P2\n",
        "    - Total time:\n",
        "      1. 2 seconds for P0 and P2 to both finish, then the first communication happens.\n",
        "      2. 3 seconds for P0 to handel data from P2\n",
        "      3. Now we can directly receive data from P1\n",
        "      4. Total 8 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBw_HeC9dc8Q"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "#include <chrono>\n",
        "\n",
        "// Recv version\n",
        "// Switch to prob version by change below to true\n",
        "bool use_probe = false;\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if (numprocs != 3) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 3 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "   // parallel task:\n",
        "   // pretend that different tasks take different time\n",
        "   if(myid == 0) sleep(2);\n",
        "   else if(myid == 1) sleep(5);\n",
        "   else if(myid == 2) sleep(1);\n",
        "\n",
        "   // gathering results to processor 0\n",
        "\n",
        "   if (myid == 1) {\n",
        "      int message = 123;\n",
        "      MPI_Send(&message, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 1 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 2) {\n",
        "      int message = 321;\n",
        "      MPI_Send(&message, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n",
        "      std::cout << \"Processor 2 sent message: \" << message << std::endl;\n",
        "   }\n",
        "   else if (myid == 0) {\n",
        "      int received_message;\n",
        "      // in this loop, the data from processor 1 will be received first\n",
        "      for(int i = 1 ; i <= 2; i++)\n",
        "      {\n",
        "         MPI_Status status;\n",
        "\n",
        "\n",
        "         // Recv version\n",
        "         if(!use_probe)\n",
        "         {\n",
        "            MPI_Recv(&received_message, 1, MPI_INT, i, i, MPI_COMM_WORLD, &status);\n",
        "            std::cout << \"Processor \" << myid << \" received message: \" << received_message << \" from processor \" << status.MPI_SOURCE << \" with tag \" << status.MPI_TAG << std::endl;\n",
        "         }\n",
        "         // Probe version\n",
        "         else\n",
        "         {\n",
        "            MPI_Probe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n",
        "            int count;\n",
        "            MPI_Get_count(&status, MPI_INT, &count);\n",
        "            MPI_Recv(&received_message, count, MPI_INT, status.MPI_SOURCE, status.MPI_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "            std::cout << \"Processor \" << myid << \" received message: \" << received_message << \" from processor \" << status.MPI_SOURCE << \" with tag \" << status.MPI_TAG << std::endl;\n",
        "         }\n",
        "\n",
        "\n",
        "         // pretend that we need to process the received data\n",
        "         sleep(3);\n",
        "      }\n",
        "      auto end = std::chrono::high_resolution_clock::now();\n",
        "      std::chrono::duration<double> elapsed = end - start;\n",
        "      std::cout << \"Total time: \" << elapsed.count() << \" seconds\" << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOlQpCvAd3CQ"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2NLAYakcIBA"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 3 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXXz6WmFXvS5"
      },
      "source": [
        "# 5.4 Example of different send/recv time and count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4jlAmjaX0qq"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <complex>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if (numprocs != 2) {\n",
        "      if (myid == 0) {\n",
        "        std::cerr << \"Error: This program requires exactly 2 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   if (myid == 0) {\n",
        "      std::vector<float> send(8);\n",
        "      for(int i = 0; i < 8; i++)\n",
        "      {\n",
        "         send[i] = i;\n",
        "      }\n",
        "      std::cout << \"Processor 0 sent message: \" << std::endl;\n",
        "      for(int i = 0; i < 8; i++)\n",
        "      {\n",
        "         std::cout << send[i] << \" \";\n",
        "      }\n",
        "      std::cout << std::endl;\n",
        "      MPI_Send(send.data(), 8, MPI_FLOAT, 1, 0, MPI_COMM_WORLD);\n",
        "   }\n",
        "   else if (myid == 1) {\n",
        "      std::vector<std::complex<float>> received(4);\n",
        "      MPI_Recv(received.data(), 4, MPI_COMPLEX, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "      std::cout << \"Processor 1 received message: \" << std::endl;\n",
        "      for(int i = 0; i < 4; i++)\n",
        "      {\n",
        "         std::cout << received[i] << \" \";\n",
        "      }\n",
        "      std::cout << std::endl;\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOmKhhG6Ytpl"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93g8Qpw5Yvec"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 2 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNu9nP_jXFlY"
      },
      "source": [
        "# 6. Reduce\n",
        "\n",
        "Reduction. In the following example:\n",
        " - If run with -np 4\n",
        " - x is 0 1 2 3\n",
        " - sum is init to 10086\n",
        " - Sum x and put results to sum on processor 0\n",
        " - So the sum on processor 0 is changed to 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2qB2kHFRYDN"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   int x = myid;\n",
        "   int sum = 10086;\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before Reduce, processor \" << myid << \" has x = \" << x << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Reduce(&x, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Reduce, processor \" << myid << \" has sum = \" << sum << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "   MPI_Finalize();\n",
        "\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AljUJMlFRbUr"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4kGK-JBRcCt"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-OcBRtZYhh"
      },
      "source": [
        "# 7 Scatter and scatter v\n",
        "\n",
        "Question: how to scatter 4 5 6 7 (on P1)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzsVftv1ZXwm"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   int *x = new int[numprocs];\n",
        "   int *y = new int[1];\n",
        "   for(int i = 0; i < numprocs; i++)\n",
        "   {\n",
        "      x[i] = i + myid * numprocs;\n",
        "   }\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before Scatter, processor \" << myid << \" has x = \";\n",
        "         for(int i = 0; i < numprocs; i++)\n",
        "         {\n",
        "            std::cout << x[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Scatter(x, 1, MPI_INT, y, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   std::cout<<\"Processor \"<<myid<<\" has \" <<y[0] <<std::endl;\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7C77MVcZbs3"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ4qOmSKZdpq"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxHH47B1a9aB"
      },
      "source": [
        "Scatterv example:\n",
        " - x: 0 1 2 3 4 5 6\n",
        " - P0:\n",
        "    - disp: 0\n",
        "    - length: 2\n",
        "    - start from x[0], send x[0] and x[1]\n",
        " - P1:\n",
        "    - disp: 2\n",
        "    - length: 2\n",
        "    - start from x[2], send x[2] and x[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A-5p95uZ62L"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   if(numprocs != 4)\n",
        "   {\n",
        "      if(myid == 0)\n",
        "      {\n",
        "         std::cout << \"Error: This program requires exactly 4 processors.\" << std::endl;\n",
        "      }\n",
        "      MPI_Finalize();\n",
        "      return 1;\n",
        "   }\n",
        "\n",
        "   int sendcount[4] = {2,2,1,1};\n",
        "   int displs[4] = {0,2,4,5};\n",
        "   float x[6];\n",
        "   for(int i = 0; i < 6; i++)\n",
        "   {\n",
        "      x[i] = i;\n",
        "   }\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Before Scatterv, processor \" << myid << \" has x = \";\n",
        "      for(int i = 0; i < 6; i++)\n",
        "      {\n",
        "         std::cout << x[i] << \" \";\n",
        "      }\n",
        "      std::cout << std::endl;\n",
        "   }\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "   float *y = new float[sendcount[myid]];\n",
        "   MPI_Scatterv(x, sendcount, displs, MPI_FLOAT, y, sendcount[myid], MPI_FLOAT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Scatterv, processor \" << myid << \" has y = \";\n",
        "         for(int i = 0; i < sendcount[myid]; i++)\n",
        "         {\n",
        "            std::cout << y[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdpcfXccae10"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdLnCLO5afnd"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0s6PYxpbepl"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   int *x = new int[2*numprocs];\n",
        "   int *y = new int[2];\n",
        "   for(int i = 0; i < 2; i++)\n",
        "   {\n",
        "      y[i] = i + myid * 2;\n",
        "   }\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before Gather, processor \" << myid << \" has y = \";\n",
        "         for(int i = 0; i < 2; i++)\n",
        "         {\n",
        "            std::cout << y[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Gather(y, 2, MPI_INT, x, 2, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Gather, processor \" << myid << \" has x = \";\n",
        "         for(int i = 0; i < 2*numprocs; i++)\n",
        "         {\n",
        "            std::cout << x[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI5oZAWfbf-G"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB9P-qe3bh-s"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7aH6YjvY2sa"
      },
      "source": [
        "# 8 All to all\n",
        "\n",
        "Like a transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR5uovqhSVPV"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "#include <unistd.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   if(myid == 0)\n",
        "   {\n",
        "      std::cout << \"Number of processors: \" << numprocs << std::endl;\n",
        "   }\n",
        "\n",
        "   int *x = new int[numprocs];\n",
        "   for(int i = 0; i < numprocs; i++)\n",
        "   {\n",
        "      x[i] = i + myid * numprocs;\n",
        "   }\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before all-to-all broadcast, processor \" << myid << \" has x = \";\n",
        "         for(int i = 0; i < numprocs; i++)\n",
        "         {\n",
        "            std::cout << x[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Alltoall(MPI_IN_PLACE, 1, MPI_INT, x, 1, MPI_INT, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After all-to-all broadcast, processor \" << myid << \" has x = \";\n",
        "         for(int i = 0; i < numprocs; i++)\n",
        "         {\n",
        "            std::cout << x[i] << \" \";\n",
        "         }\n",
        "         std::cout << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "235ddUVJSYr0"
      },
      "outputs": [],
      "source": [
        "!mpicxx main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q-uzbmXSam3"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNuotWJZZMnQ"
      },
      "source": [
        "# 9 Allreduce\n",
        "\n",
        "Reduce + bcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCkaM4mzY1Dk"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cpp\n",
        "#include <mpi.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "   MPI_Init(&argc, &argv);\n",
        "\n",
        "   int myid, numprocs;\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &myid);\n",
        "\n",
        "   int x = myid;\n",
        "   int sum = 10086;\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"Before Allreduce, processor \" << myid << \" has x = \" << x << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "\n",
        "   MPI_Allreduce(&x, &sum, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n",
        "\n",
        "   for(int id = 0 ; id < numprocs; id++)\n",
        "   {\n",
        "      if(myid == id)\n",
        "      {\n",
        "         std::cout << \"After Allreduce, processor \" << myid << \" has sum = \" << sum << std::endl;\n",
        "      }\n",
        "      MPI_Barrier(MPI_COMM_WORLD);\n",
        "   }\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "\n",
        "   MPI_Finalize();\n",
        "\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyeApy7nY4Vd"
      },
      "outputs": [],
      "source": [
        "!mpiCC main.cpp -o main.ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LcCI-UcY4_S"
      },
      "outputs": [],
      "source": [
        "!mpirun --oversubscribe --allow-run-as-root -np 4 ./main.ex"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
